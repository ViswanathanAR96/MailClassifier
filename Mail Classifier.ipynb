{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text\n",
      "0   ham   enron methanol ; meter # : 988291\\r\\nthis is ...\n",
      "1   ham   hpl nom for january 9 , 2001\\r\\n( see attache...\n",
      "2   ham   neon retreat\\r\\nho ho ho , we ' re around to ...\n",
      "3  spam   photoshop , windows , office . cheap . main t...\n",
      "4   ham   re : indian springs\\r\\nthis deal is to book t...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = \"{0}/spam_ham_dataset.csv\".format(os.getcwd())\n",
    "#Read csv file\n",
    "data = pd.read_csv(data_path)[['label', 'text']]\n",
    "print(data.head())\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in text if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['text', 'body_len', 'punct%']], data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>411</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197625</td>\n",
       "      <td>0.187939</td>\n",
       "      <td>0.105454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239137</td>\n",
       "      <td>0.116250</td>\n",
       "      <td>0.050764</td>\n",
       "      <td>0.029308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065330</td>\n",
       "      <td>0.065330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084083</td>\n",
       "      <td>0.083596</td>\n",
       "      <td>0.018104</td>\n",
       "      <td>0.034113</td>\n",
       "      <td>0.109968</td>\n",
       "      <td>0.073690</td>\n",
       "      <td>0.020916</td>\n",
       "      <td>0.030190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104268</td>\n",
       "      <td>0.103665</td>\n",
       "      <td>0.035546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172733</td>\n",
       "      <td>0.054257</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154710</td>\n",
       "      <td>0.154710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216147</td>\n",
       "      <td>0.156289</td>\n",
       "      <td>0.080387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.102249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023959</td>\n",
       "      <td>0.023959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121721</td>\n",
       "      <td>0.266237</td>\n",
       "      <td>0.124489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169382</td>\n",
       "      <td>0.050671</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>0.138396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2         3         4    5    6    7  ...  \\\n",
       "0       411     6.6  0.0  0.0  0.0  0.084564  0.084564  0.0  0.0  0.0  ...   \n",
       "1       605    14.7  0.0  0.0  0.0  0.065330  0.065330  0.0  0.0  0.0  ...   \n",
       "2       185     5.4  0.0  0.0  0.0  0.085515  0.085515  0.0  0.0  0.0  ...   \n",
       "3       195     4.1  0.0  0.0  0.0  0.154710  0.154710  0.0  0.0  0.0  ...   \n",
       "4       135     0.7  0.0  0.0  0.0  0.023959  0.023959  0.0  0.0  0.0  ...   \n",
       "\n",
       "         31        32        33        34        35        36        37  \\\n",
       "0  0.197625  0.187939  0.105454  0.000000  0.239137  0.116250  0.050764   \n",
       "1  0.084083  0.083596  0.018104  0.034113  0.109968  0.073690  0.020916   \n",
       "2  0.104268  0.103665  0.035546  0.000000  0.172733  0.054257  0.041068   \n",
       "3  0.216147  0.156289  0.080387  0.000000  0.117188  0.102249  0.000000   \n",
       "4  0.121721  0.266237  0.124489  0.000000  0.169382  0.050671  0.028765   \n",
       "\n",
       "         38   39        40  \n",
       "0  0.029308  0.0  0.000000  \n",
       "1  0.030190  0.0  0.000000  \n",
       "2  0.019759  0.0  0.035992  \n",
       "3  0.178733  0.0  0.000000  \n",
       "4  0.138396  0.0  0.000000  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['text'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['text'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['body_len', 'punct%']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "X_test_vect = pd.concat([X_test[['body_len', 'punct%']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random ForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 1.146 / Predict time: 0.082 ---- Precision: 0.863 / Recall: 0.736 / Accuracy: 0.893\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 21.224 / Predict time: 0.02 ---- Precision: 0.86 / Recall: 0.777 / Accuracy: 0.901\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "start = time.time()\n",
    "gb_model = gb.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gb_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 0.117 / Predict time: 0.003 ---- Precision: 0.787 / Recall: 0.582 / Accuracy: 0.838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viswanathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lor = LogisticRegression()\n",
    "start = time.time()\n",
    "lor_model = lor.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = lor_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: uniform / Algo: ball_tree / Neighbors: 5 / Fit time: 0.05 / Predict time: 0.082 ---- Precision: 0.469 / Recall: 0.308 / Accuracy: 0.706\n",
      "Weight: uniform / Algo: ball_tree / Neighbors: 10 / Fit time: 0.045 / Predict time: 0.062 ---- Precision: 0.523 / Recall: 0.192 / Accuracy: 0.723\n",
      "Weight: uniform / Algo: ball_tree / Neighbors: 15 / Fit time: 0.035 / Predict time: 0.133 ---- Precision: 0.468 / Recall: 0.199 / Accuracy: 0.71\n",
      "Weight: uniform / Algo: ball_tree / Neighbors: 20 / Fit time: 0.037 / Predict time: 0.067 ---- Precision: 0.516 / Recall: 0.161 / Accuracy: 0.721\n",
      "Weight: uniform / Algo: ball_tree / Neighbors: 30 / Fit time: 0.035 / Predict time: 0.072 ---- Precision: 0.529 / Recall: 0.123 / Accuracy: 0.722\n",
      "Weight: uniform / Algo: ball_tree / Neighbors: 50 / Fit time: 0.041 / Predict time: 0.086 ---- Precision: 0.596 / Recall: 0.116 / Accuracy: 0.729\n",
      "Weight: uniform / Algo: kd_tree / Neighbors: 5 / Fit time: 0.066 / Predict time: 0.087 ---- Precision: 0.469 / Recall: 0.308 / Accuracy: 0.706\n",
      "Weight: uniform / Algo: kd_tree / Neighbors: 10 / Fit time: 0.063 / Predict time: 0.063 ---- Precision: 0.523 / Recall: 0.192 / Accuracy: 0.723\n",
      "Weight: uniform / Algo: kd_tree / Neighbors: 15 / Fit time: 0.055 / Predict time: 0.067 ---- Precision: 0.468 / Recall: 0.199 / Accuracy: 0.71\n",
      "Weight: uniform / Algo: kd_tree / Neighbors: 20 / Fit time: 0.065 / Predict time: 0.065 ---- Precision: 0.516 / Recall: 0.161 / Accuracy: 0.721\n",
      "Weight: uniform / Algo: kd_tree / Neighbors: 30 / Fit time: 0.055 / Predict time: 0.075 ---- Precision: 0.529 / Recall: 0.123 / Accuracy: 0.722\n",
      "Weight: uniform / Algo: kd_tree / Neighbors: 50 / Fit time: 0.058 / Predict time: 0.077 ---- Precision: 0.596 / Recall: 0.116 / Accuracy: 0.729\n",
      "Weight: uniform / Algo: brute / Neighbors: 5 / Fit time: 0.008 / Predict time: 0.185 ---- Precision: 0.469 / Recall: 0.308 / Accuracy: 0.706\n",
      "Weight: uniform / Algo: brute / Neighbors: 10 / Fit time: 0.01 / Predict time: 0.182 ---- Precision: 0.523 / Recall: 0.192 / Accuracy: 0.723\n",
      "Weight: uniform / Algo: brute / Neighbors: 15 / Fit time: 0.012 / Predict time: 0.211 ---- Precision: 0.468 / Recall: 0.199 / Accuracy: 0.71\n",
      "Weight: uniform / Algo: brute / Neighbors: 20 / Fit time: 0.008 / Predict time: 0.191 ---- Precision: 0.516 / Recall: 0.161 / Accuracy: 0.721\n",
      "Weight: uniform / Algo: brute / Neighbors: 30 / Fit time: 0.011 / Predict time: 0.208 ---- Precision: 0.529 / Recall: 0.123 / Accuracy: 0.722\n",
      "Weight: uniform / Algo: brute / Neighbors: 50 / Fit time: 0.009 / Predict time: 0.188 ---- Precision: 0.596 / Recall: 0.116 / Accuracy: 0.729\n",
      "Weight: distance / Algo: ball_tree / Neighbors: 5 / Fit time: 0.045 / Predict time: 0.022 ---- Precision: 0.468 / Recall: 0.346 / Accuracy: 0.704\n",
      "Weight: distance / Algo: ball_tree / Neighbors: 10 / Fit time: 0.049 / Predict time: 0.027 ---- Precision: 0.491 / Recall: 0.291 / Accuracy: 0.715\n",
      "Weight: distance / Algo: ball_tree / Neighbors: 15 / Fit time: 0.043 / Predict time: 0.031 ---- Precision: 0.474 / Recall: 0.253 / Accuracy: 0.71\n",
      "Weight: distance / Algo: ball_tree / Neighbors: 20 / Fit time: 0.041 / Predict time: 0.028 ---- Precision: 0.514 / Recall: 0.257 / Accuracy: 0.722\n",
      "Weight: distance / Algo: ball_tree / Neighbors: 30 / Fit time: 0.036 / Predict time: 0.024 ---- Precision: 0.543 / Recall: 0.216 / Accuracy: 0.728\n",
      "Weight: distance / Algo: ball_tree / Neighbors: 50 / Fit time: 0.032 / Predict time: 0.032 ---- Precision: 0.551 / Recall: 0.185 / Accuracy: 0.728\n",
      "Weight: distance / Algo: kd_tree / Neighbors: 5 / Fit time: 0.065 / Predict time: 0.019 ---- Precision: 0.468 / Recall: 0.346 / Accuracy: 0.704\n",
      "Weight: distance / Algo: kd_tree / Neighbors: 10 / Fit time: 0.058 / Predict time: 0.02 ---- Precision: 0.491 / Recall: 0.291 / Accuracy: 0.715\n",
      "Weight: distance / Algo: kd_tree / Neighbors: 15 / Fit time: 0.075 / Predict time: 0.028 ---- Precision: 0.474 / Recall: 0.253 / Accuracy: 0.71\n",
      "Weight: distance / Algo: kd_tree / Neighbors: 20 / Fit time: 0.061 / Predict time: 0.023 ---- Precision: 0.514 / Recall: 0.257 / Accuracy: 0.722\n",
      "Weight: distance / Algo: kd_tree / Neighbors: 30 / Fit time: 0.054 / Predict time: 0.025 ---- Precision: 0.543 / Recall: 0.216 / Accuracy: 0.728\n",
      "Weight: distance / Algo: kd_tree / Neighbors: 50 / Fit time: 0.056 / Predict time: 0.048 ---- Precision: 0.551 / Recall: 0.185 / Accuracy: 0.728\n",
      "Weight: distance / Algo: brute / Neighbors: 5 / Fit time: 0.007 / Predict time: 0.205 ---- Precision: 0.468 / Recall: 0.346 / Accuracy: 0.704\n",
      "Weight: distance / Algo: brute / Neighbors: 10 / Fit time: 0.018 / Predict time: 0.229 ---- Precision: 0.491 / Recall: 0.291 / Accuracy: 0.715\n",
      "Weight: distance / Algo: brute / Neighbors: 15 / Fit time: 0.007 / Predict time: 0.125 ---- Precision: 0.474 / Recall: 0.253 / Accuracy: 0.71\n",
      "Weight: distance / Algo: brute / Neighbors: 20 / Fit time: 0.011 / Predict time: 0.137 ---- Precision: 0.514 / Recall: 0.257 / Accuracy: 0.722\n",
      "Weight: distance / Algo: brute / Neighbors: 30 / Fit time: 0.008 / Predict time: 0.131 ---- Precision: 0.543 / Recall: 0.216 / Accuracy: 0.728\n",
      "Weight: distance / Algo: brute / Neighbors: 50 / Fit time: 0.01 / Predict time: 0.147 ---- Precision: 0.551 / Recall: 0.185 / Accuracy: 0.728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "weights = ['uniform', 'distance']\n",
    "algos = ['ball_tree', 'kd_tree', 'brute']\n",
    "neighs = [5, 10, 15, 20, 30, 50]\n",
    "for weight in weights:\n",
    "    for algo in algos:\n",
    "        for neigh in neighs:\n",
    "            knn = KNeighborsClassifier(weights = weight, algorithm = algo, n_neighbors = neigh)\n",
    "            start = time.time()\n",
    "            knn_model = knn.fit(X_train_vect, y_train)\n",
    "            end = time.time()\n",
    "            fit_time = (end - start)\n",
    "\n",
    "            start = time.time()\n",
    "            y_pred = knn_model.predict(X_test_vect)\n",
    "            end = time.time()\n",
    "            pred_time = (end - start)\n",
    "\n",
    "            precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "            print('Weight: {} / Algo: {} / Neighbors: {} / Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(weight,\n",
    "                algo, neigh, round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
